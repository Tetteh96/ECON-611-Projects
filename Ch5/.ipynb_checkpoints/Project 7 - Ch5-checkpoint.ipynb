{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 5: Probability Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Probability__ takes on a value from 0 to 1, with a probability $P(X) = 0$ for an event meaning that the stated condition - e.g., a standard 6 sided die will yield a 7 when rolled -  would never occur in an infinite number of flips. A probability of 0.5 means that in a sufficiently large number of trials, approximately half of the trials would result in the stated condition. A probability of 1 means all trials would result in the stated condition so that the number of successes in a trial would be equal to the number of attempts. \n",
    "\n",
    "__Probability Distributions__ display all of the possible values that a _random variable_ $X$ could take on on the x-axis, and the corresponding probability of that value on the y-axis. Hence, the area under the probability distribution will always be equal to one. \n",
    "   - The random variable $\\bar{X}$, which represents the the mean of a sample drawn from a larger population, defines a _**sampling distribution**_, which gives all values possible for $\\bar{X}$, $\\bar{X_i}$, and the probability of that value occuring. $\\bar{X}$ can take on values falling on its sampling distribution, which describe the likelihood of getting a given mean for a given sample size.  This sampling distribution takes on a standard deviation of $\\frac{S}{\\sqrt(n)}$, otherwise known as the **standard error.** \n",
    "\n",
    "Distributions can be described by: \n",
    "- Their mean, $\\mu$(or $\\bar{X}$ for sampling distributions), which is the average value of the dataset.  \n",
    "- Their standard deviation, $\\sigma$, which determines how flat the curve is, and how densely the data clusters around the mean(SE for sampling distributions).\n",
    "- Skewness, $S_{KP}$, which refers to a distortion or asymmetry of a distribution. \n",
    "- Kurtosis, $k$, which describes how much of the distribution lays in its tails. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of Probability Distributions\n",
    "#### Normal Distributions\n",
    "Normal Distribution, also known as Gaussian distribution, is ubiquitous in Data Science and often used when modeling economic phenomena. You will encounter it in predictive models you create. It is one of the assumptions of many statistical techniques.\n",
    "\n",
    "A normal distribution has a bell-shaped density curve described by its mean $\\mu$ and standard deviation $\\sigma$. The density curve is symmetrical(skewness of 0), centered about its mean, with its spread determined by its standard deviation. Data near the mean - e.g., $\\sigma < 1$ - are more frequent in occurrence than data far from the mean - e.g., $\\sigma > 2$. \n",
    "\n",
    "\n",
    "A random variable $X$ which follows a normal distribution with mean $\\mu$ and standard deviation $\\sigma$ and has this density function: \n",
    "<h3 align=\"center\">\n",
    "    <font size=\"4\">\n",
    "        $ X = \\frac{1}{\\sigma\\sqrt{2\\pi}}e^{-\\frac{1}{2}(\\frac{x-\\mu}{\\sigma})^2} $\n",
    "    </font>\n",
    "    </h3> \n",
    "    \n",
    "If one knew the mean and standard deviation of a particular distribution, it would be possible to estimate the probability of drawing a value from a particular range - e.g., $a \\leq X \\leq b$ - by taking the definite integral of this function: \n",
    "<h3 align=\"center\">\n",
    "    <font size=\"4\">\n",
    "        $\\int_{a}^{b}\\frac{1}{\\sigma\\sqrt{2\\pi}}e^{-\\frac{1}{2}(\\frac{x-\\mu}{\\sigma})^2}dx$.\n",
    "    </font>\n",
    "</h3>\n",
    "\n",
    "#### Standard Normal Distribution\n",
    "\n",
    "The standardized normal distribution is the most important member of the family of normal probability distributions—the one with $\\mu = 0$  and $\\sigma = 1$. The normal random variable distributed according to the standard normal distribution is called the standard normal variable and is denoted by $Z$. It represents the number of standard deviations a given point X lies from the mean of the standard normal distribution.  It is expressed as\n",
    "<h3 align=\"center\">\n",
    "    <font size=\"4\">\n",
    "        $ Z =  \\frac{X-\\mu}{\\sigma}$\n",
    "    </h3> \n",
    "\n",
    "A key feature of all normal distributions is that, using the equation above, they can be transformed to be analyzed using the standard normal distribution.\n",
    "    \n",
    "_If you divide any normal distribution by its standard deviation(normalizing the SD to be 1), that normal distribution becomes the standard normal distribution._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from stats import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes a list fo x values in a given range with some number of finite\n",
    "# divisions, will create a y value that correlates with each x value that was passed\n",
    "def normal_dist(mean, sd, x = np.linspace(-10, 10, 1000)):\n",
    "    prob_density = 1 / (sd * (2 * np.pi) ** .5) * np.exp(-0.5 * ((x - mean) / sd) ** 2)\n",
    "    return prob_density\n",
    "\n",
    "normal_dist_list = normal_dist(mean = 0, sd = 1)\n",
    "plt.plot(normal_dist_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size' : 24})\n",
    "fig, axs = plt.subplots(3, 1, figsize = (16, 24))\n",
    "x = np.linspace(-10, 10, 1000)\n",
    "\n",
    "# perform transformation\n",
    "# Setting mean and standard deviation variables to 0 and 1, respectively\n",
    "mean_, sd = 0, 1\n",
    "\n",
    "# Generating a list of values for the normal distribution with mean and standard deviation defined above\n",
    "normal_dist_list = normal_dist(mean=0, sd=1, x=x)\n",
    "\n",
    "# Plotting the normal distribution on the first subplot\n",
    "axs[0].plot(x, normal_dist_list)\n",
    "\n",
    "# Setting the title of the first subplot to include the mean and standard deviation values\n",
    "axs[0].set_title('Normal Distribution \\n $\\mu$ =' + str(mean_) +  ', $\\sigma$ =' + str(sd))\n",
    "\n",
    "# Initializing empty strings and subplots for the second and third plots\n",
    "ax1_title = ''\n",
    "ax1_sub = 0\n",
    "ax2_title = '$\\mu$ = 0'\n",
    "ax2_sub = 0\n",
    "\n",
    "# Looping through a range of mean values from -3 to 3 in steps of 2\n",
    "for mean_ in range(-3, 4, 2):\n",
    "    # Setting standard deviation to be the absolute value of the current mean value\n",
    "    sd = abs(mean_)\n",
    "    \n",
    "    # Generating a list of values for the normal distribution with the current mean and standard deviation values\n",
    "    normal_dist_list = normal_dist(mean=mean_, sd=sd, x=x)\n",
    "    \n",
    "    # Plotting the normal distribution on the second subplot\n",
    "    axs[1].plot(x, normal_dist_list)\n",
    "    \n",
    "    # Updating the title of the second subplot to include the mean and standard deviation values\n",
    "    ax1_title = ax1_title + '$\\mu_' + str(ax1_sub) + '$ = ' + str(mean_) + ', '\n",
    "    ax1_title = ax1_title + '$\\sigma_' + str(ax1_sub) + '$ = ' + str(sd) + '\\t '\n",
    "    ax1_sub += 1\n",
    "    \n",
    "# Setting the title of the second subplot to the updated title string\n",
    "axs[1].set_title(ax1_title)\n",
    "\n",
    "# Looping through a range of standard deviation values from 1 to 3\n",
    "for sd in range(1, 4):\n",
    "    # Setting mean value to 0\n",
    "    mean_ = 0\n",
    "    \n",
    "    # Generating a list of values for the normal distribution with the current mean and standard deviation values\n",
    "    normal_dist_list = normal_dist(mean=mean_, sd=sd, x=x)\n",
    "    \n",
    "    # Plotting the normal distribution on the third subplot\n",
    "    axs[2].plot(x, normal_dist_list)\n",
    "    \n",
    "    # Updating the title of the third subplot to include the standard deviation value\n",
    "    ax2_title = ax2_title + '\\t $\\sigma_' + str(ax2_sub) + '$ = ' + str(sd) + ' '\n",
    "    ax2_sub =+ 1\n",
    "    \n",
    "# Setting the title of the third subplot to the updated title string\n",
    "axs[2].set_title(ax2_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lognormal Distribution\n",
    "\n",
    "A random variable $X$ is said to have a lognormal distribution if $Y = ln(X)$ is normally distributed, where $ln$ denotes the natural logarithm.\n",
    "\n",
    "In other words, $X$ is log-normally distributed if the natural logarithm of $X$ is normally distributed with mean $\\mu$  and variance $\\sigma ^2$:\n",
    "\n",
    "$ln(X) = N(\\mu, \\sigma^2)$\n",
    "\n",
    "The lognormal distribution is positively skewed with many small values and just a few large values. Consequently, the mean is greater than the mode in most cases.\n",
    "Since the lognormal distribution is bound by zero on the lower side, it is perfect for modeling asset prices that cannot take negative values. On the other hand, the normal distribution cannot be used for the same purpose because it has a negative side.\n",
    "\n",
    "When the returns on a stock (continuously compounded) follow a normal distribution(as shown above), the stock prices follow a lognormal distribution. Note that even if returns do not follow a normal distribution, the lognormal distribution is still the most appropriate model for stock prices.\n",
    "\n",
    "The probability density function of the distribution is:\n",
    "<h3 align=\"center\">\n",
    "    <font size=\"4\">\n",
    "        $f(x) = \\frac{1}{x\\sigma\\sqrt{2\\pi}}e^{\\frac{- (lnx-\\mu)^2}{2\\sigma^2}}$\n",
    "    </font>\n",
    "    </h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Optionally, pass different array of x values tp be transformed; default is np.linspace(-5, 5, 1000)\n",
    "\n",
    "# Defining a function that takes in a mean, standard deviation, and an optional array of x values\n",
    "def create_lognormal(mean, sd, x = np.linspace(0, 10, 1000)):\n",
    "    # Calculating the density values for each x value using the log-normal distribution formula\n",
    "    density_points = (1 / x * sd * np.sqrt(2 * math.pi)) * math.e ** (\n",
    "        -(np.log(x) - mean) ** 2 / (2 * sd ** 2))\n",
    "    # Returning the calculated density values\n",
    "    return density_points\n",
    "\n",
    "# Generating an array of 1000 x values between 0 and 10\n",
    "x = np.linspace(0, 10, 1000)\n",
    "\n",
    "# Setting mean and standard deviation variables to 1 each\n",
    "mean, sd = 1,1\n",
    "\n",
    "# Calling the create_lognormal function with the defined mean, standard deviation, and x values\n",
    "log_norm = create_lognormal(mean = mean, sd = sd, x = x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (24, 16))\n",
    "ax.plot(x, log_norm)\n",
    "ax.set_title('Lognormal Distribution with μ = ' + str(mean) + ' and σ = ' + str(sd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (24, 16))\n",
    "ax.plot(x, log_norm)\n",
    "plt.xscale('log')\n",
    "ax.set_title('Lognormal Distribution with μ = ' + str(mean) + ' and σ = ' + str(sd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binomial Distribution\n",
    "If $X$ is a random variable that yields the number of successess seen in the trials of a binomial(yes or no) experiment, then we say that $X$ follows a binomial distribution.\n",
    "\n",
    "We are interested in finding the probability that some particular number of successes is seen in the course of that binomial experiment.\n",
    "\n",
    "- $n$ = the number of trials\n",
    "- $x$ = some number of successes, with $0≤x≤n$\n",
    "- $p$ = the probability of success on any one trial\n",
    "- $q$ = $1−p$ = the probability of failure on any one trial\n",
    "\n",
    "A binomial trial can result in a success with probability $p$ and a failure with probability $q = 1−p$. Then the probability distribution of the binomial random variable $X$, the number of successes in $n$ independent trials, is\n",
    "<h3 align=\"center\">\n",
    "    <font size=\"4\">\n",
    "        $b(x; n, p) = {n \\choose x}p^xq^{n-x}$\n",
    "    </font>\n",
    "    </h3> \n",
    "\n",
    "Where  $x = 0, 1, 2,..., n$ and ${n \\choose x}=\\frac{n!}{x!(n-x)!}$\n",
    "\n",
    "The most common example is flipping a coin, which can be modeled as $x=$ the number of \"heads\" or \"tails\" in $n$ trials. The probability of success and failure is 0.5. \n",
    "\n",
    "The mean $\\mu$ and standard deviation $\\sigma$ for a binomial distribution $b(x; n, p)$ are\n",
    "- $\\mu = np$\n",
    "- $\\sigma = \\sqrt{np(1-p)}$\n",
    "\n",
    "We define and graph the binomial distribution for various x, p, and n values. \n",
    "\n",
    "As an example of the binomial distribution, we can think of the top hedge funds in the stock market. If we assume that the markets are efficient and any given mutual fund only has a 50% probability of beating the market in every year, if there is a large $n$, or a large number of firms, many of them will survive for many years, just by chance. This example is demonstrated wonderfully in Burton Malkiel's *A Random Walk Down Wallstreet* in which he describes a coin flipping contest of 1000 people, which guarantees that multiple people will win more than 10 rounds simply by chance, and then become world-renouned as amazing coin-flippers. \n",
    "\n",
    "- How many funds will 'beat' an efficient market for more than 10 years if there are 1000 funds to start? We will find the probability of a single fund beating the market for that long and then multiply that by 1000 funds. \n",
    "\n",
    "- $ = P(1) = {10 \\choose 1}0.5^{1}0.5^{10-1} = 0.0097$, so there is a 0.97% chance of a single fund beating an efficient market for 10 years, and we can reasonably expect that 97 funds will beat the market for 10 years if 100 start, just by chance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binomial(x, n, p):\n",
    "    # Calculating the probability of failure\n",
    "    q = 1 - p\n",
    "    # Using the binomial distribution formula to calculate the probability of x successes in n trials with probability of success p\n",
    "    return float(math.factorial(n)) / (\n",
    "                math.factorial(int(x)) * math.factorial(n - int(x))) * p ** x * q ** (n - int(x))\n",
    "\n",
    "\n",
    "    #return float(math.factorial(n)) / (\n",
    "        #math.factorial(x) * math.factorial(n-x)) * p ** x * q ** (n - x)\n",
    "binomial(x = 50, n = 100, p =.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probability of generating a total betwenn X0 and X1 for a given p, n\n",
    "def probability_of_outcome(X0, X1, p, n):\n",
    "    P = 0\n",
    "    for x in range(X0, X1 + 1):\n",
    "        P += binomial(x = x, n = n, p = p) \n",
    "    return P\n",
    "\n",
    "p, n = .5, 100\n",
    "X0 = 40\n",
    "X1 = 60\n",
    "\n",
    "probability_of_outcome(X0, X1, p, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (24, 16))\n",
    "cmap = cm.get_cmap('Blues')\n",
    "ymax = binomial(20 * p, 20, p)\n",
    "for n in range(20, 101, 20):\n",
    "#     x = int(n * p)\n",
    "    # make a list of probability of every possible outcome\n",
    "    #  from 0 to n\n",
    "    binom_vars = [binomial(x, n, p) for x in range(n + 1)]\n",
    "    # plot_line that is composed of all probabilities\n",
    "    plt.plot(binom_vars, \n",
    "             linewidth = 3,\n",
    "            label=f'n={n}, p={p}')\n",
    "# change max y axis value from 1 to the something closer to the maximum\n",
    "#  probabity across all range from 0 to n for which we constructed \n",
    "#  distributions\n",
    "ax.set_ylim(ymin = 0, ymax = ymax)\n",
    "\n",
    "plt.xlabel('$x$\\nIncreasing n ------------------------------------------->',\n",
    "           fontsize=24)\n",
    "plt.ylabel('$p(x | p, n)$', fontsize=24)\n",
    "plt.title('Binomial Distribution B(x;n,p) for various p and n Values')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with Time Series Data\n",
    "\n",
    "We will be working with stock price data. This data is an instance of time series data. The structure of untransformed time series data often violates the requirements of a random variable that observations be:\n",
    "\n",
    "1. identitically distributed \n",
    "2. independent\n",
    "\n",
    "To be identitically distributed means that observations are drawn from the same distribution. To be independent means that neighboring observations should not mutually influence one another. The independence criterion is typically violated for a single variable. Further, if two variables are subject to the I.I.D. assumptions, then not only must observations from a sample be subject to this criterion, but so too observations of the two variables must not be correlated. Here, we will show that individual samples are identically distributed. In a Chapter 6, we will be able to test whether or not the draws are observations of a given sample are independent of their neighbors. And in chpater 7, we will later consider the I.I.D. assumption when working with multiple variables using Ordinary Least Squares regression.\n",
    "\n",
    "We will first show that unstransformed stock data is not identically distributed. But first, we need to download the data. We will use *pandas_datareader* to access yahoo finance. If you have not used this module before, install it using the command:\n",
    "\n",
    "> *pip install pandas-datareader*\n",
    "\n",
    "If you want to install this library from within Jupyter notebook, use:\n",
    "\n",
    "> *!pip install pandas-datareader*\n",
    "\n",
    "Note: A recent update to yahoo finance has broken the ability of pandas-datareader download yahoo finance data. A patch has been added to the github. If the above installation does not work, use:\n",
    "\n",
    ">  *pip install git+https://github.com/raphi6/pandas-datareader.git@ea66d6b981554f9d0262038aef2106dda7138316*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_datareader.data as web\n",
    "import yfinance as yf\n",
    "import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "yf.pdr_override()\n",
    "start = datetime.datetime(2012, 1, 1)\n",
    "end = datetime.datetime.today()\n",
    "\n",
    "data_dict = {}\n",
    "stocks = ['MSFT', 'AAPL', 'PG', 'TSLA']\n",
    "for stock in stocks:\n",
    "    data_dict[stock] = web.get_data_yahoo(stock, start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict['MSFT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "[df['Close'] for df in data_dict.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_data = pd.concat([df['Close'] for df in data_dict.values()],\n",
    "                        keys = data_dict.keys(),\n",
    "                        axis = 1)\n",
    "\n",
    "close_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Setting the x margin to 0 and the y margin to .01 for the plot\n",
    "plt.rcParams['axes.xmargin'] = 0\n",
    "plt.rcParams['axes.ymargin'] = .01\n",
    "\n",
    "# Updating the font size to 32 for the plot\n",
    "plt.rcParams.update({'font.size' : 32})\n",
    "\n",
    "# Creating a figure and axes for the plot with a size of 24 by 16 inches\n",
    "fig, ax = plt.subplots(figsize = (24, 16))\n",
    "\n",
    "# Plotting the close data on a line graph on the given axes and showing the legend\n",
    "close_data.plot.line(ax = ax, legend = True)\n",
    "\n",
    "# Setting the title of the plot to \"Daily Stock Prices\"\n",
    "ax.set_title('Daily Stock Prices')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data appears to be quite volatile. This is because we are viewing data in observed units rather than comparing changes in proportional terms. If we log the axis, we will see that the data actually is much more stable than would be suggested by the above graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (24, 16))\n",
    "close_data.plot.line(ax = ax, legend = True)\n",
    "ax.set_title('Daily Stock Prices')\n",
    "ax.set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It may not be obvious that this data is not normally distributed. To clarify this, let's create a histogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (24, 16))\n",
    "stock = 'AAPL'\n",
    "close_data['AAPL'].hist(bins = [i for i in range(10, 201, 5)])\n",
    "#close_data['AAPL'].hist(bins = 50)\n",
    "ax.set_title(stock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_data = np.log(close_data)\n",
    "log_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (24, 16))\n",
    "log_data[stock].hist(bins = 50)\n",
    "ax.set_title(stock, fontsize= 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's replot the data, separating observations by year and indicating the means of each year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_yearly_distribution(data, stock, figsize = (24, 16), density = False):\n",
    "    # Extracting the years from the data's index and sorting them\n",
    "    years = sorted(list(set(data.index.year)))\n",
    "    # Creating a figure and axes for the plot with the given figure size\n",
    "    fig, ax = plt.subplots(figsize = figsize)\n",
    "    # Looping through each year in the sorted list of years\n",
    "    for year in years:\n",
    "        # Choosing a color based on the year modulo 12, and converting the year to a string\n",
    "        color = 'C' + str(year % 12)\n",
    "        year = str(year)\n",
    "        # Selecting the data for the given stock for the current year and plotting it as a histogram on the axes, with various customizations\n",
    "        plot_data = data[stock].loc[year]\n",
    "        plot_data.plot.hist(color = color,\n",
    "                            alpha = .6,\n",
    "                            label = year,\n",
    "                            bins = 20,\n",
    "                            density = density,\n",
    "                            ax = ax)\n",
    "        # Adding a vertical line at the mean value of the current year's data with the same color as the histogram\n",
    "        ax.axvline(plot_data.mean(),\n",
    "                    color = color,\n",
    "                    linewidth = 5,\n",
    "                    ls = '--')\n",
    "        # Setting the title of the plot to the given stock name\n",
    "        ax.set_title(stock)\n",
    "        # Adding a legend to the plot at the top-right corner outside of the axes\n",
    "        ax.legend(bbox_to_anchor = (1, 1))\n",
    "\n",
    "# Calling the function to create a histogram of the yearly distribution of the given stock's log data, with density set to False\n",
    "graph_yearly_distribution(log_data, stock, density = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_change_data = log_data.diff()\n",
    "price_change_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_yearly_distribution(price_change_data, stock, density= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These distributions drawn from annual data do not appear at all to converge upon a normal distribution, neither do these distributions have consistent mean value. Let's transform the data so that we observe the distribution of the daily rate of change of stock prices. We will take the difference of the log values to approximate the daily rate of change of the stock price. This will make the data more closely conform to the assumption that it is identically distributed. \n",
    "\n",
    "If the efficient markets hypothesis is correct in any form, the distribution of daily price changes should be approximately normally distributed. We will see that, over the long-run, the hypothesis is true, but over the short-run, we may find that the tails of distributions are relatively fat, that some stocks violate this assumption, and that daily price changes are often autocorrelated. Further, the absolute value of daily price changes is also autocorrelated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (24, 16))\n",
    "stock = 'AAPL'\n",
    "#price_change_mean = f'{price_change_data[stock].mean():.3f}'\n",
    "price_change_mean = round(price_change_data[stock].mean(), 3)\n",
    "price_change_data[stock].dropna().plot.hist(bins = 50, density = True)\n",
    "ax.set_title(stock + '\\nMean:' + str(price_change_mean), fontsize = 20)\n",
    "ax.axvline(price_change_mean, color = 'k', linewidth = 3, ls = '--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (24, 16))\n",
    "for key in price_change_data.keys():\n",
    "    price_change_data[key].plot.line(marker = '.', markersize = 12,\n",
    "                                    alpha = .6,\n",
    "                                    ls = '',\n",
    "                                    ax = ax)\n",
    "ax.set_title('Daily Price Change (%)')\n",
    "\n",
    "# access y-axis values\n",
    "y_vals = ax.get_yticks()\n",
    "\n",
    "# transform y-axis values to be in the form of percent instead of decimal\n",
    "ax.set_yticklabels([str(round(y * 100, 1)) + '%' for y in y_vals])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stats import *\n",
    "\n",
    "stats_df = gather_statistics(price_change_data.mul(100),\n",
    "                            sample = True).round(2)\n",
    "\n",
    "stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import table\n",
    "\n",
    "# axs is a list of list\n",
    "# sublists contains relevant axes that comprise the multiplot\n",
    "fig, axs = plt.subplots(2, 2, figsize = (24, 16))\n",
    "price_change_data.hist(bins = 50,\n",
    "                        alpha = .3,\n",
    "                        label = price_change_data.keys(),\n",
    "                        ax = axs,\n",
    "                        density = False)\n",
    "\n",
    "# adjust xtick labels in a multiplot by using a for loop\n",
    "# to access sublists\n",
    "for sublist in axs:\n",
    "# and access elements in sublist   \n",
    "    # Looping through each axis in the sublist\n",
    "    for ax in sublist:\n",
    "        \n",
    "        # Getting the x tick values and setting the tick labels to be percentage values with one decimal place\n",
    "        x_vals = ax.get_xticks()\n",
    "        ax.set_xticklabels([str(round(x * 100, 1)) + '%' for x in x_vals], rotation = 45)\n",
    "\n",
    "        # Getting the stock name from the axis title and extracting the corresponding data from the stats_df dataframe\n",
    "        stock = ax.get_title()\n",
    "        hist_data = stats_df[stock]\n",
    "\n",
    "        # Creating a table to display statistical information about the data on the axis\n",
    "        stats = table(ax, hist_data, colWidths = [.1], cellColours = [[(.9,.9,.9)]] * 6, loc = 'upper right')\n",
    "        \n",
    "        # Scaling the size of the table, disabling automatic font sizing, setting the font size, and turning off the axis grid\n",
    "        stats.scale(1.25, 2.5)\n",
    "        stats.auto_set_font_size(False)\n",
    "        stats.set_fontsize(20)\n",
    "        ax.grid(False)\n",
    "\n",
    "        #print(stock, price_change_data[stock].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# measure data in terms of standard deviation\n",
    "\n",
    "price_change_data.div(price_change_data.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiply the price change data by 100\n",
    "plot_data = price_change_data.mul(100)\n",
    "\n",
    "# Create a figure with a large size\n",
    "fig, ax = plt.subplots(figsize=(24, 16))\n",
    "\n",
    "# Loop through each key in the price_change_data and plot a histogram\n",
    "for key in price_change_data:\n",
    "    # Set the number of bins to be the length of 1%\n",
    "    plot_data[key].hist(bins=[x for x in range(-22, 22, 1)],\n",
    "                        alpha=.2,\n",
    "                        label=key,\n",
    "                        density=False,\n",
    "                        ax=ax)\n",
    "\n",
    "# Set the y-axis label\n",
    "ax.set_ylabel('Days per Bin')\n",
    "\n",
    "# Set the tick labels for the x-axis to be percentages\n",
    "x_vals = ax.get_xticks()\n",
    "ax.set_xticklabels([str(int(x)) + '%' for x in x_vals])\n",
    "\n",
    "# Create a table showing the standard deviation for each stock\n",
    "std_df = round(plot_data.std(), 2).rename('S.D').to_frame()\n",
    "stats = table(ax,\n",
    "              std_df,\n",
    "              colWidths=[.1],\n",
    "              cellColours=[[(.9,.9,.9)]]*4,\n",
    "              loc=\"center right\")\n",
    "stats.scale(.8, 4)\n",
    "stats.auto_set_font_size(False)\n",
    "stats.set_fontsize(30)\n",
    "\n",
    "# Remove the grid lines from the plot\n",
    "ax.grid(False)\n",
    "\n",
    "# Add a legend to the plot\n",
    "ax.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_plot_data = price_change_data.div(price_change_data.std())\n",
    "norm_plot_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replot normalization data by standard deviation\n",
    "fig, ax = plt.subplots(figsize = (24, 16))\n",
    "for key in norm_plot_data:\n",
    "    norm_plot_data[key].hist(bins = [x / 4 for x in range(-28, 29, 1)],\n",
    "                            alpha = .2,\n",
    "                            label = key,\n",
    "                            # setting density 'True' shows frequency units of SDs\n",
    "                            density = True,\n",
    "                            ax = ax)\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_xlabel('$\\sigma$', fontsize = 50)\n",
    "\n",
    "# If this is a normal distribution, 95% of the body of the distribution should lie between -1.96 and 1.96 SD of the mean\n",
    "ax.axvline(-1.96, linewidth = 5, ls = '--', color = 'k', alpha = .7)\n",
    "ax.axvline(1.96, linewidth = 5, ls = '--', color = 'k', alpha = .7)\n",
    "ax.grid(False)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_change_data['S&P 500'] = web.get_data_yahoo('^GSPC',\n",
    "                                                start,\n",
    "                                                end)['Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_change_data['S&P 500'] = np.log(price_change_data['S&P 500']).diff()\n",
    "price_change_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_beta(data, stock_key, market_key):\n",
    "    # Select the columns with data and drop missing values\n",
    "    df = data[[stock_key, market_key]].dropna()\n",
    "    \n",
    "    # Calculate the covariance between the stock and the market\n",
    "    stock_cov = covariance(df[stock_key], df[market_key], sample = True) \n",
    "    \n",
    "    # Calculate the variance of the market\n",
    "    stock_var = variance(df[market_key], sample = True)\n",
    "    \n",
    "    # Calculate beta as the ratio of the covariance to the variance\n",
    "    beta = stock_cov / stock_var\n",
    "    \n",
    "    return beta\n",
    "    \n",
    "# Initialize empty dictionary for betas\n",
    "betas = {}\n",
    "\n",
    "# Iterate over all stocks and calculate their beta with respect to S&P 500\n",
    "for stock in stocks:\n",
    "    betas[stock] = calculate_beta(price_change_data, stock, 'S&P 500')\n",
    "\n",
    "# Create a pandas DataFrame to display the betas\n",
    "pd.DataFrame(betas, index = ['$\\\\beta$']).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = price_change_data.mul(100)\n",
    "for stock in stocks:\n",
    "    fig, ax = plt.subplots(2, 1, figsize = (24, 24))\n",
    "    plot_data['S&P 500'].hist(bins = [x for x in range(-10, 11, 1)],\n",
    "                                label = 'S&P Daily Returns; $\\\\beta$ = ' + str(1),\n",
    "                                ax = ax[0],\n",
    "                                density = False,\n",
    "                                alpha = .65)\n",
    "\n",
    "    plot_data[stock].hist(bins=[x for x in range(-10, 11, 1)],\n",
    "                            label=stock + ' Daily Returns; $\\\\beta$ = ' + str(round(betas[stock], 2)),\n",
    "                            ax=ax[0],\n",
    "                            density=False,\n",
    "                            alpha=0.5)\n",
    "\n",
    "\n",
    "    ax[0].legend(bbox_to_anchor = (.45, 1.3))\n",
    "    ax[0].set_ylabel('Days')\n",
    "    ax[0].set_xlabel('Price Change')\n",
    "    ax[0].set_xticklabels([str(x) + '%' for x in ax[0].get_xticks()])\n",
    "    ax[0].grid(False)\n",
    "\n",
    "    plot_data[stock].plot(linestyle = '-',\n",
    "                                linewidth = 1,\n",
    "                                marker = 'o',\n",
    "                                markersize = 4,\n",
    "                                color = 'C1',\n",
    "                                ax = ax[1])\n",
    "    \n",
    "    plot_data['S&P 500'].plot(linestyle = '',\n",
    "                                marker = 'o',\n",
    "                                markersize = 4,\n",
    "                                color = 'C0',\n",
    "                                ax = ax[1])\n",
    "\n",
    "    ax[1].set_ylabel('Price Change')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "m = 1000\n",
    "\n",
    "dist_avgs = {'Die Rolls' : [],\n",
    "            'Poisson' : [],\n",
    "            'Lognormal' : []}\n",
    "\n",
    "# build a sample of m means from distributions of length n\n",
    "for i in range(m):\n",
    "    dist_avgs['Die Rolls'].append(mean(np.random.randint(1, 7, n)))\n",
    "    dist_avgs['Poisson'].append(mean(np.random.poisson(1, n)))\n",
    "    dist_avgs['Lognormal'].append(mean(np.random.lognormal(0, 1, n)))\n",
    "# each column is a sample of sample means\n",
    "dist_avgs = pd.DataFrame(dist_avgs)\n",
    "dist_avgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure and axis object with a size of 20x20\n",
    "fig, ax = plt.subplots(figsize = (20, 20))\n",
    "\n",
    "# Plot histograms of the distributions in dist_avgs with 20 bins,\n",
    "# density normalized, and colored by C1, C2, and C3 with 50% transparency\n",
    "dist_avgs.plot.hist(density = True,\n",
    "                    ax = ax,\n",
    "                    bins = 20,\n",
    "                    color = ['C1', 'C2', 'C3'],\n",
    "                    alpha = .5,\n",
    "                    legend = False)\n",
    "\n",
    "# Plot kernel density estimates of the distributions in dist_avgs\n",
    "# colored by C1, C2, and C3, and remove the legend\n",
    "dist_avgs.plot.kde(ax = ax, color = ['C1', 'C2', 'C3'], legend = False)\n",
    "\n",
    "# Set the title of the plot\n",
    "ax.set_title('Non-Centered Distributions')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "means_df = pd.DataFrame()\n",
    "sd_df = pd.DataFrame()\n",
    "\n",
    "for key in dist_avgs:\n",
    "    ## Center Distribution\n",
    "    # df that centers the distribution at zero by substracting the mean value from each sample mean\n",
    "    means_df[key] = dist_avgs[key].sub(dist_avgs.mean()[key])\n",
    "\n",
    "    ## Normalize Distribution\n",
    "    # divide each observation \n",
    "    sd_df[key] = means_df[key] / means_df.std()[key]\n",
    "\n",
    "sd_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_dct = {'Non-Centered Distributions' : dist_avgs,\n",
    "#         'Centered Distributions' : means_df,\n",
    "#         'Centered Distributions Normalized by SD' : sd_df}\n",
    "\n",
    "# keys = list(df_dct.keys())\n",
    "\n",
    "# # Create a figure and axis object with a size of 20x20\n",
    "# num_figs = len(keys)\n",
    "# fig, axs = plt.subplots(num_figs, figsize = (10, 20))\n",
    "\n",
    "# for i in range(num_figs):\n",
    "#     key = keys[i]\n",
    "#     ax = axs[i]\n",
    "#     plot_df = df_dct[key]\n",
    "#     num_samples = len(plot_df.keys())\n",
    "#     colors = ['C' + str(c + 1) for c in range(num_samples)]\n",
    "\n",
    "# # Plot histograms of the distributions in dist_avgs with 20 bins,\n",
    "# # density normalized, and colored by C1, C2, and C3 with 50% transparency\n",
    "# plot_df.plot.hist(density = True,\n",
    "#                     ax = ax,\n",
    "#                     bins = 20,\n",
    "#                     color = colors,\n",
    "#                     alpha = .5,\n",
    "#                     legend = False)\n",
    "\n",
    "# # Plot kernel density estimates of the distributions in dist_avgs\n",
    "# # colored by C1, C2, and C3, and remove the legend\n",
    "# plot_df.plot.kde(ax = ax, color = colors, legend = False)\n",
    "\n",
    "# # Set the title of the plot\n",
    "# ax.set_title(key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save df in a single dictionary\n",
    "df_dct = {\n",
    "    'Non-Centered Distributions': dist_avgs,\n",
    "    'Centered Distributions': means_df,\n",
    "    'Centered Distributions Normalized by SD': sd_df\n",
    "}\n",
    "\n",
    "# use the keys in the dictionary to call each of the df\n",
    "keys = list(df_dct.keys())\n",
    "\n",
    "# automatically count the number of keys in the dictionary\n",
    "num_figs = len(keys)\n",
    "\n",
    "fig, axs = plt.subplots(num_figs, figsize=(10, 20))\n",
    "\n",
    "# using for loop with the dictionary of df's will allow us to\n",
    "# automate the creation of a multiplot\n",
    "# cycle through each index value in the list of keys\n",
    "for i, key in enumerate(keys):\n",
    "    # select ax by index value\n",
    "    ax = axs[i]\n",
    "    # select dataframe that is linked to key\n",
    "    plot_df = df_dct[key]\n",
    "    # count the number of columns inthe dataframe\n",
    "    # this is the number of distributions \n",
    "    num_samples = len(plot_df.columns)\n",
    "    # each distribution will be assigned to its own color\n",
    "    colors = ['C' + str(c + 1) for c in range(num_samples)]\n",
    "    \n",
    "    #first, plot the dataframe containing the distributions of the random sample means\n",
    "    plot_df.plot.hist(density=True,\n",
    "                       ax=ax,\n",
    "                       bins=20,\n",
    "                       color=colors,\n",
    "                       alpha=.5,\n",
    "                       legend=False)\n",
    "    \n",
    "    # fit the distribution curve on the relevant data\n",
    "    plot_df.plot.kde(ax=ax, color=colors, legend=False)\n",
    "    ax.set_title(key)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "line = np.array([i + 3 for i in range(100)])\n",
    "points = []\n",
    "for point in line:\n",
    "    points.append(random.normalvariate(mu = point, sigma = point))\n",
    "figure = plt.figure(figsize= (12, 6))\n",
    "plt.plot(line, label = 'Truth')\n",
    "plt.scatter(np.arange(len(points)),\n",
    "             points,\n",
    "             label = 'Points drawn\\nfrom Normal Distibution',\n",
    "             s = 10)\n",
    "plt.title('Randomly Generate\\nPoints about a Line')\n",
    "plt.legend(loc = 'best', fontsize = 22)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_random_data_with_line(y_int, slope, SD = 1):\n",
    "    line = np.array([slope * (i) + y_int for i in range(100)])\n",
    "    points = []\n",
    "    for point in line:\n",
    "        points.append(random.normalvariate(point, SD))\n",
    "    return line, points\n",
    "\n",
    "def plot_line(line, points, line_name = 'Truth',\n",
    "            title = 'Randomly Generated Points'):\n",
    "\n",
    "    figure = plt.figure(figsize = (20, 10))\n",
    "    plt.plot(line, label = line_name)\n",
    "    plt.scatter(np.arange(len(points)), points, s = 10,\n",
    "                label = title)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.legend(loc = 'best', fontsize = 22)\n",
    "    plt.show()\n",
    "\n",
    "line, points = build_random_data_with_line(y_int = 10, slope = -1, SD = 10)\n",
    "plot_line(line, points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single simulation\n",
    "\n",
    "random_list  = [random.normalvariate(0, .5) for i in range (1000)]\n",
    "fig, axs = plt.subplots(2, figsize = (20, 16))\n",
    "axs[0].plot(random_list, ls = '', marker = '.', markersize = 10)\n",
    "\n",
    "simulation = []\n",
    "for i in range(len(random_list)):\n",
    "    val =random_list[i]\n",
    "    if i == 0:\n",
    "        simulation.append(val)\n",
    "    else:\n",
    "        # add last value observed in simulation + change(which is val)\n",
    "        # this will generate the latest value in the simulation\n",
    "        simulation.append(simulation[-1] + val)\n",
    "axs[1].plot(simulation)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
